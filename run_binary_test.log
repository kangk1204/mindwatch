/home/deargen/Projects/06_MentalHealth_AI_Depression_JJLee/05_main_run/src/train_tft.py:143: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  dt = pd.to_datetime(df[col], errors="coerce")
/home/deargen/Projects/06_MentalHealth_AI_Depression_JJLee/05_main_run/src/train_tft.py:143: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  dt = pd.to_datetime(df[col], errors="coerce")
/home/deargen/Projects/06_MentalHealth_AI_Depression_JJLee/05_main_run/src/train_tft.py:135: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  timestamps = pd.to_datetime(df["timestamp"], errors="coerce", utc=True)
/home/deargen/miniconda3/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/deargen/miniconda3/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  3.63it/s]Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.63it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training: |          | 0/? [00:00<?, ?it/s]Epoch 0:   0%|          | 0/68 [00:00<?, ?it/s]Epoch 0:   1%|â–         | 1/68 [00:00<00:15,  4.21it/s]Epoch 0:   1%|â–         | 1/68 [00:00<00:15,  4.21it/s, v_num=17, train_loss_step=1.020]Epoch 0:   3%|â–Ž         | 2/68 [00:00<00:09,  7.29it/s, v_num=17, train_loss_step=1.020]Epoch 0:   3%|â–Ž         | 2/68 [00:00<00:09,  7.29it/s, v_num=17, train_loss_step=0.873]Epoch 0:   4%|â–         | 3/68 [00:00<00:06,  9.54it/s, v_num=17, train_loss_step=0.873]Epoch 0:   4%|â–         | 3/68 [00:00<00:06,  9.54it/s, v_num=17, train_loss_step=0.805]Epoch 0:   6%|â–Œ         | 4/68 [00:00<00:05, 11.31it/s, v_num=17, train_loss_step=0.805]Epoch 0:   6%|â–Œ         | 4/68 [00:00<00:05, 11.31it/s, v_num=17, train_loss_step=0.747]Epoch 0:   7%|â–‹         | 5/68 [00:00<00:05, 12.46it/s, v_num=17, train_loss_step=0.747]Epoch 0:   7%|â–‹         | 5/68 [00:00<00:05, 12.45it/s, v_num=17, train_loss_step=0.735]Epoch 0:   9%|â–‰         | 6/68 [00:00<00:04, 13.37it/s, v_num=17, train_loss_step=0.735]Epoch 0:   9%|â–‰         | 6/68 [00:00<00:04, 13.36it/s, v_num=17, train_loss_step=0.720]Epoch 0:  10%|â–ˆ         | 7/68 [00:00<00:04, 14.26it/s, v_num=17, train_loss_step=0.720]Epoch 0:  10%|â–ˆ         | 7/68 [00:00<00:04, 14.25it/s, v_num=17, train_loss_step=0.707]Epoch 0:  12%|â–ˆâ–        | 8/68 [00:00<00:04, 14.77it/s, v_num=17, train_loss_step=0.707]Epoch 0:  12%|â–ˆâ–        | 8/68 [00:00<00:04, 14.77it/s, v_num=17, train_loss_step=0.706]Epoch 0:  13%|â–ˆâ–Ž        | 9/68 [00:00<00:03, 15.43it/s, v_num=17, train_loss_step=0.706]Epoch 0:  13%|â–ˆâ–Ž        | 9/68 [00:00<00:03, 15.43it/s, v_num=17, train_loss_step=0.698]Epoch 0:  15%|â–ˆâ–        | 10/68 [00:00<00:03, 15.93it/s, v_num=17, train_loss_step=0.698]Epoch 0:  15%|â–ˆâ–        | 10/68 [00:00<00:03, 15.92it/s, v_num=17, train_loss_step=0.699]Epoch 0:  16%|â–ˆâ–Œ        | 11/68 [00:00<00:03, 16.15it/s, v_num=17, train_loss_step=0.699]Epoch 0:  16%|â–ˆâ–Œ        | 11/68 [00:00<00:03, 16.14it/s, v_num=17, train_loss_step=0.696]Epoch 0:  18%|â–ˆâ–Š        | 12/68 [00:00<00:03, 16.43it/s, v_num=17, train_loss_step=0.696]Epoch 0:  18%|â–ˆâ–Š        | 12/68 [00:00<00:03, 16.42it/s, v_num=17, train_loss_step=0.698]Epoch 0:  19%|â–ˆâ–‰        | 13/68 [00:00<00:03, 16.56it/s, v_num=17, train_loss_step=0.698]Epoch 0:  19%|â–ˆâ–‰        | 13/68 [00:00<00:03, 16.56it/s, v_num=17, train_loss_step=0.696]Epoch 0:  21%|â–ˆâ–ˆ        | 14/68 [00:00<00:03, 16.80it/s, v_num=17, train_loss_step=0.696]Epoch 0:  21%|â–ˆâ–ˆ        | 14/68 [00:00<00:03, 16.80it/s, v_num=17, train_loss_step=0.695]Epoch 0:  22%|â–ˆâ–ˆâ–       | 15/68 [00:00<00:03, 17.07it/s, v_num=17, train_loss_step=0.695]Epoch 0:  22%|â–ˆâ–ˆâ–       | 15/68 [00:00<00:03, 17.07it/s, v_num=17, train_loss_step=0.696]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 16/68 [00:00<00:02, 17.38it/s, v_num=17, train_loss_step=0.696]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 16/68 [00:00<00:02, 17.38it/s, v_num=17, train_loss_step=0.696]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 17/68 [00:00<00:02, 17.43it/s, v_num=17, train_loss_step=0.696]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 17/68 [00:00<00:02, 17.43it/s, v_num=17, train_loss_step=0.695]Epoch 0:  26%|â–ˆâ–ˆâ–‹       | 18/68 [00:01<00:02, 17.74it/s, v_num=17, train_loss_step=0.695]Epoch 0:  26%|â–ˆâ–ˆâ–‹       | 18/68 [00:01<00:02, 17.74it/s, v_num=17, train_loss_step=0.695]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 19/68 [00:01<00:02, 18.10it/s, v_num=17, train_loss_step=0.695]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 19/68 [00:01<00:02, 18.10it/s, v_num=17, train_loss_step=0.695]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 20/68 [00:01<00:02, 18.36it/s, v_num=17, train_loss_step=0.695]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 20/68 [00:01<00:02, 18.35it/s, v_num=17, train_loss_step=0.695]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 21/68 [00:01<00:02, 18.57it/s, v_num=17, train_loss_step=0.695]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 21/68 [00:01<00:02, 18.57it/s, v_num=17, train_loss_step=0.695]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 22/68 [00:01<00:02, 18.65it/s, v_num=17, train_loss_step=0.695]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 22/68 [00:01<00:02, 18.65it/s, v_num=17, train_loss_step=0.694]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 23/68 [00:01<00:02, 18.67it/s, v_num=17, train_loss_step=0.694]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 23/68 [00:01<00:02, 18.67it/s, v_num=17, train_loss_step=0.694]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 24/68 [00:01<00:02, 18.89it/s, v_num=17, train_loss_step=0.694]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 24/68 [00:01<00:02, 18.89it/s, v_num=17, train_loss_step=0.694]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/68 [00:01<00:02, 19.04it/s, v_num=17, train_loss_step=0.694]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/68 [00:01<00:02, 19.04it/s, v_num=17, train_loss_step=0.694]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 26/68 [00:01<00:02, 19.09it/s, v_num=17, train_loss_step=0.694]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 26/68 [00:01<00:02, 19.09it/s, v_num=17, train_loss_step=0.695]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 27/68 [00:01<00:02, 19.18it/s, v_num=17, train_loss_step=0.695]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 27/68 [00:01<00:02, 19.17it/s, v_num=17, train_loss_step=0.694]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 28/68 [00:01<00:02, 19.24it/s, v_num=17, train_loss_step=0.694]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 28/68 [00:01<00:02, 19.24it/s, v_num=17, train_loss_step=0.694]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 29/68 [00:01<00:02, 19.30it/s, v_num=17, train_loss_step=0.694]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 29/68 [00:01<00:02, 19.29it/s, v_num=17, train_loss_step=0.694]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/68 [00:01<00:01, 19.37it/s, v_num=17, train_loss_step=0.694]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/68 [00:01<00:01, 19.36it/s, v_num=17, train_loss_step=0.694]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 31/68 [00:01<00:01, 19.41it/s, v_num=17, train_loss_step=0.694]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 31/68 [00:01<00:01, 19.40it/s, v_num=17, train_loss_step=0.694]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 32/68 [00:01<00:01, 19.45it/s, v_num=17, train_loss_step=0.694]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 32/68 [00:01<00:01, 19.45it/s, v_num=17, train_loss_step=0.694]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 33/68 [00:01<00:01, 19.43it/s, v_num=17, train_loss_step=0.694]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 33/68 [00:01<00:01, 19.43it/s, v_num=17, train_loss_step=0.694]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 34/68 [00:01<00:01, 19.44it/s, v_num=17, train_loss_step=0.694]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 34/68 [00:01<00:01, 19.43it/s, v_num=17, train_loss_step=0.694]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/68 [00:01<00:01, 19.46it/s, v_num=17, train_loss_step=0.694]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/68 [00:01<00:01, 19.46it/s, v_num=17, train_loss_step=0.694]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 36/68 [00:01<00:01, 19.56it/s, v_num=17, train_loss_step=0.694]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 36/68 [00:01<00:01, 19.56it/s, v_num=17, train_loss_step=0.694]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 37/68 [00:01<00:01, 19.61it/s, v_num=17, train_loss_step=0.694]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 37/68 [00:01<00:01, 19.61it/s, v_num=17, train_loss_step=0.694]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 38/68 [00:01<00:01, 19.60it/s, v_num=17, train_loss_step=0.694]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 38/68 [00:01<00:01, 19.60it/s, v_num=17, train_loss_step=0.694]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 39/68 [00:01<00:01, 19.68it/s, v_num=17, train_loss_step=0.694]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 39/68 [00:01<00:01, 19.67it/s, v_num=17, train_loss_step=0.694]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/68 [00:02<00:01, 19.67it/s, v_num=17, train_loss_step=0.694]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/68 [00:02<00:01, 19.67it/s, v_num=17, train_loss_step=0.694]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/68 [00:02<00:01, 19.76it/s, v_num=17, train_loss_step=0.694]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/68 [00:02<00:01, 19.76it/s, v_num=17, train_loss_step=0.694]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 42/68 [00:02<00:01, 19.82it/s, v_num=17, train_loss_step=0.694]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 42/68 [00:02<00:01, 19.82it/s, v_num=17, train_loss_step=0.694]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 43/68 [00:02<00:01, 19.81it/s, v_num=17, train_loss_step=0.694]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 43/68 [00:02<00:01, 19.81it/s, v_num=17, train_loss_step=0.694]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 44/68 [00:02<00:01, 19.83it/s, v_num=17, train_loss_step=0.694]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 44/68 [00:02<00:01, 19.83it/s, v_num=17, train_loss_step=0.694]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 45/68 [00:02<00:01, 19.89it/s, v_num=17, train_loss_step=0.694]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 45/68 [00:02<00:01, 19.89it/s, v_num=17, train_loss_step=0.694]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 46/68 [00:02<00:01, 19.90it/s, v_num=17, train_loss_step=0.694]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 46/68 [00:02<00:01, 19.90it/s, v_num=17, train_loss_step=0.694]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 47/68 [00:02<00:01, 19.93it/s, v_num=17, train_loss_step=0.694]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 47/68 [00:02<00:01, 19.92it/s, v_num=17, train_loss_step=0.694]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 48/68 [00:02<00:01, 19.97it/s, v_num=17, train_loss_step=0.694]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 48/68 [00:02<00:01, 19.97it/s, v_num=17, train_loss_step=0.694]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 49/68 [00:02<00:00, 20.09it/s, v_num=17, train_loss_step=0.694]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 49/68 [00:02<00:00, 20.09it/s, v_num=17, train_loss_step=0.694]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 50/68 [00:02<00:00, 20.16it/s, v_num=17, train_loss_step=0.694]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 50/68 [00:02<00:00, 20.16it/s, v_num=17, train_loss_step=0.694]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/68 [00:02<00:00, 20.18it/s, v_num=17, train_loss_step=0.694]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/68 [00:02<00:00, 20.18it/s, v_num=17, train_loss_step=0.694]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 52/68 [00:02<00:00, 20.18it/s, v_num=17, train_loss_step=0.694]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 52/68 [00:02<00:00, 20.18it/s, v_num=17, train_loss_step=0.694]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 53/68 [00:02<00:00, 20.22it/s, v_num=17, train_loss_step=0.694]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 53/68 [00:02<00:00, 20.22it/s, v_num=17, train_loss_step=0.693]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 54/68 [00:02<00:00, 20.22it/s, v_num=17, train_loss_step=0.693]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 54/68 [00:02<00:00, 20.22it/s, v_num=17, train_loss_step=0.694]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 55/68 [00:02<00:00, 20.23it/s, v_num=17, train_loss_step=0.694]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 55/68 [00:02<00:00, 20.23it/s, v_num=17, train_loss_step=0.694]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 56/68 [00:02<00:00, 20.23it/s, v_num=17, train_loss_step=0.694]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 56/68 [00:02<00:00, 20.23it/s, v_num=17, train_loss_step=0.694]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 57/68 [00:02<00:00, 20.21it/s, v_num=17, train_loss_step=0.694]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 57/68 [00:02<00:00, 20.20it/s, v_num=17, train_loss_step=0.694]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 58/68 [00:02<00:00, 20.23it/s, v_num=17, train_loss_step=0.694]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 58/68 [00:02<00:00, 20.23it/s, v_num=17, train_loss_step=0.694]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 59/68 [00:02<00:00, 20.27it/s, v_num=17, train_loss_step=0.694]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 59/68 [00:02<00:00, 20.27it/s, v_num=17, train_loss_step=0.694]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 60/68 [00:02<00:00, 20.31it/s, v_num=17, train_loss_step=0.694]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 60/68 [00:02<00:00, 20.31it/s, v_num=17, train_loss_step=0.694]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 61/68 [00:02<00:00, 20.35it/s, v_num=17, train_loss_step=0.694]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 61/68 [00:02<00:00, 20.35it/s, v_num=17, train_loss_step=0.694]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 62/68 [00:03<00:00, 20.39it/s, v_num=17, train_loss_step=0.694]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 62/68 [00:03<00:00, 20.39it/s, v_num=17, train_loss_step=0.694]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 63/68 [00:03<00:00, 20.42it/s, v_num=17, train_loss_step=0.694]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 63/68 [00:03<00:00, 20.42it/s, v_num=17, train_loss_step=0.694]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 64/68 [00:03<00:00, 20.45it/s, v_num=17, train_loss_step=0.694]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 64/68 [00:03<00:00, 20.45it/s, v_num=17, train_loss_step=0.694]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 65/68 [00:03<00:00, 20.45it/s, v_num=17, train_loss_step=0.694]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 65/68 [00:03<00:00, 20.45it/s, v_num=17, train_loss_step=0.694]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 66/68 [00:03<00:00, 20.43it/s, v_num=17, train_loss_step=0.694]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 66/68 [00:03<00:00, 20.43it/s, v_num=17, train_loss_step=0.693]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 67/68 [00:03<00:00, 20.48it/s, v_num=17, train_loss_step=0.693]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 67/68 [00:03<00:00, 20.48it/s, v_num=17, train_loss_step=0.694]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:03<00:00, 20.53it/s, v_num=17, train_loss_step=0.694]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:03<00:00, 20.53it/s, v_num=17, train_loss_step=0.694]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/18 [00:00<?, ?it/s][A
Validation DataLoader 0:   6%|â–Œ         | 1/18 [00:00<00:00, 49.11it/s][A
Validation DataLoader 0:  11%|â–ˆ         | 2/18 [00:00<00:00, 52.37it/s][A
Validation DataLoader 0:  17%|â–ˆâ–‹        | 3/18 [00:00<00:00, 53.44it/s][A
Validation DataLoader 0:  22%|â–ˆâ–ˆâ–       | 4/18 [00:00<00:00, 48.38it/s][A
Validation DataLoader 0:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:00<00:00, 50.91it/s][A
Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:00<00:00, 50.06it/s][A
Validation DataLoader 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:00<00:00, 52.18it/s][A
Validation DataLoader 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:00<00:00, 53.98it/s][A
Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:00<00:00, 55.47it/s][A
Validation DataLoader 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:00<00:00, 56.93it/s][A
Validation DataLoader 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:00<00:00, 56.80it/s][A
Validation DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:00<00:00, 57.97it/s][A
Validation DataLoader 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:00<00:00, 58.98it/s][A
Validation DataLoader 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:00<00:00, 58.67it/s][A
Validation DataLoader 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:00<00:00, 59.48it/s][A
Validation DataLoader 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:00<00:00, 59.75it/s][A
Validation DataLoader 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:00<00:00, 60.43it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 60.91it/s][A
                                                                        [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:04<00:00, 14.39it/s, v_num=17, train_loss_step=0.694, val_loss=0.694]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:04<00:00, 14.39it/s, v_num=17, train_loss_step=0.694, val_loss=0.694, train_loss_epoch=0.706]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:04<00:00, 14.38it/s, v_num=17, train_loss_step=0.694, val_loss=0.694, train_loss_epoch=0.706]ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Traceback (most recent call last):
  File "/home/deargen/Projects/06_MentalHealth_AI_Depression_JJLee/05_main_run/src/train_tft.py", line 435, in <module>
    main()
  File "/home/deargen/Projects/06_MentalHealth_AI_Depression_JJLee/05_main_run/src/train_tft.py", line 415, in main
    dropped_index = prediction_obj.index[nan_mask]
                    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
  File "/home/deargen/.local/lib/python3.12/site-packages/pandas/core/frame.py", line 4098, in __getitem__
    return self._getitem_bool_array(key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/deargen/.local/lib/python3.12/site-packages/pandas/core/frame.py", line 4148, in _getitem_bool_array
    raise ValueError(
ValueError: Item wrong length 17440 instead of 545.
