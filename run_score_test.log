/home/deargen/Projects/06_MentalHealth_AI_Depression_JJLee/05_main_run/src/train_tft.py:127: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  dt = pd.to_datetime(df[col], errors="coerce")
/home/deargen/Projects/06_MentalHealth_AI_Depression_JJLee/05_main_run/src/train_tft.py:127: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  dt = pd.to_datetime(df[col], errors="coerce")
/home/deargen/Projects/06_MentalHealth_AI_Depression_JJLee/05_main_run/src/train_tft.py:119: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  timestamps = pd.to_datetime(df["timestamp"], errors="coerce", utc=True)
/home/deargen/miniconda3/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
/home/deargen/miniconda3/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  3.57it/s]Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.67it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training: |          | 0/? [00:00<?, ?it/s]Epoch 0:   0%|          | 0/68 [00:00<?, ?it/s]Epoch 0:   1%|â–         | 1/68 [00:00<00:13,  4.99it/s]Epoch 0:   1%|â–         | 1/68 [00:00<00:13,  4.98it/s, v_num=28, train_loss_step=5.910]Epoch 0:   3%|â–Ž         | 2/68 [00:00<00:08,  7.79it/s, v_num=28, train_loss_step=5.910]Epoch 0:   3%|â–Ž         | 2/68 [00:00<00:08,  7.78it/s, v_num=28, train_loss_step=5.120]Epoch 0:   4%|â–         | 3/68 [00:00<00:06,  9.35it/s, v_num=28, train_loss_step=5.120]Epoch 0:   4%|â–         | 3/68 [00:00<00:06,  9.35it/s, v_num=28, train_loss_step=6.380]Epoch 0:   6%|â–Œ         | 4/68 [00:00<00:06, 10.55it/s, v_num=28, train_loss_step=6.380]Epoch 0:   6%|â–Œ         | 4/68 [00:00<00:06, 10.55it/s, v_num=28, train_loss_step=5.470]Epoch 0:   7%|â–‹         | 5/68 [00:00<00:05, 11.27it/s, v_num=28, train_loss_step=5.470]Epoch 0:   7%|â–‹         | 5/68 [00:00<00:05, 11.27it/s, v_num=28, train_loss_step=6.160]Epoch 0:   9%|â–‰         | 6/68 [00:00<00:05, 11.49it/s, v_num=28, train_loss_step=6.160]Epoch 0:   9%|â–‰         | 6/68 [00:00<00:05, 11.48it/s, v_num=28, train_loss_step=4.620]Epoch 0:  10%|â–ˆ         | 7/68 [00:00<00:05, 11.57it/s, v_num=28, train_loss_step=4.620]Epoch 0:  10%|â–ˆ         | 7/68 [00:00<00:05, 11.57it/s, v_num=28, train_loss_step=4.440]Epoch 0:  12%|â–ˆâ–        | 8/68 [00:00<00:05, 11.73it/s, v_num=28, train_loss_step=4.440]Epoch 0:  12%|â–ˆâ–        | 8/68 [00:00<00:05, 11.73it/s, v_num=28, train_loss_step=5.220]Epoch 0:  13%|â–ˆâ–Ž        | 9/68 [00:00<00:05, 11.76it/s, v_num=28, train_loss_step=5.220]Epoch 0:  13%|â–ˆâ–Ž        | 9/68 [00:00<00:05, 11.76it/s, v_num=28, train_loss_step=6.310]Epoch 0:  15%|â–ˆâ–        | 10/68 [00:00<00:04, 11.67it/s, v_num=28, train_loss_step=6.310]Epoch 0:  15%|â–ˆâ–        | 10/68 [00:00<00:04, 11.66it/s, v_num=28, train_loss_step=5.280]Epoch 0:  16%|â–ˆâ–Œ        | 11/68 [00:00<00:04, 11.69it/s, v_num=28, train_loss_step=5.280]Epoch 0:  16%|â–ˆâ–Œ        | 11/68 [00:00<00:04, 11.69it/s, v_num=28, train_loss_step=6.500]Epoch 0:  18%|â–ˆâ–Š        | 12/68 [00:01<00:04, 11.89it/s, v_num=28, train_loss_step=6.500]Epoch 0:  18%|â–ˆâ–Š        | 12/68 [00:01<00:04, 11.89it/s, v_num=28, train_loss_step=4.280]Epoch 0:  19%|â–ˆâ–‰        | 13/68 [00:01<00:04, 12.02it/s, v_num=28, train_loss_step=4.280]Epoch 0:  19%|â–ˆâ–‰        | 13/68 [00:01<00:04, 12.02it/s, v_num=28, train_loss_step=5.470]Epoch 0:  21%|â–ˆâ–ˆ        | 14/68 [00:01<00:04, 12.05it/s, v_num=28, train_loss_step=5.470]Epoch 0:  21%|â–ˆâ–ˆ        | 14/68 [00:01<00:04, 12.05it/s, v_num=28, train_loss_step=4.090]Epoch 0:  22%|â–ˆâ–ˆâ–       | 15/68 [00:01<00:04, 12.00it/s, v_num=28, train_loss_step=4.090]Epoch 0:  22%|â–ˆâ–ˆâ–       | 15/68 [00:01<00:04, 12.00it/s, v_num=28, train_loss_step=5.470]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 16/68 [00:01<00:04, 12.04it/s, v_num=28, train_loss_step=5.470]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 16/68 [00:01<00:04, 12.04it/s, v_num=28, train_loss_step=5.250]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 17/68 [00:01<00:04, 11.89it/s, v_num=28, train_loss_step=5.250]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 17/68 [00:01<00:04, 11.89it/s, v_num=28, train_loss_step=5.190]Epoch 0:  26%|â–ˆâ–ˆâ–‹       | 18/68 [00:01<00:04, 11.95it/s, v_num=28, train_loss_step=5.190]Epoch 0:  26%|â–ˆâ–ˆâ–‹       | 18/68 [00:01<00:04, 11.95it/s, v_num=28, train_loss_step=5.690]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 19/68 [00:01<00:04, 11.98it/s, v_num=28, train_loss_step=5.690]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 19/68 [00:01<00:04, 11.98it/s, v_num=28, train_loss_step=4.840]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 20/68 [00:01<00:03, 12.13it/s, v_num=28, train_loss_step=4.840]Epoch 0:  29%|â–ˆâ–ˆâ–‰       | 20/68 [00:01<00:03, 12.13it/s, v_num=28, train_loss_step=5.220]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 21/68 [00:01<00:03, 12.33it/s, v_num=28, train_loss_step=5.220]Epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 21/68 [00:01<00:03, 12.33it/s, v_num=28, train_loss_step=8.160]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 22/68 [00:01<00:03, 12.52it/s, v_num=28, train_loss_step=8.160]Epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 22/68 [00:01<00:03, 12.51it/s, v_num=28, train_loss_step=4.120]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 23/68 [00:01<00:03, 12.62it/s, v_num=28, train_loss_step=4.120]Epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 23/68 [00:01<00:03, 12.62it/s, v_num=28, train_loss_step=6.720]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 24/68 [00:01<00:03, 12.69it/s, v_num=28, train_loss_step=6.720]Epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 24/68 [00:01<00:03, 12.69it/s, v_num=28, train_loss_step=3.120]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/68 [00:01<00:03, 12.79it/s, v_num=28, train_loss_step=3.120]Epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/68 [00:01<00:03, 12.79it/s, v_num=28, train_loss_step=4.060]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 26/68 [00:02<00:03, 12.82it/s, v_num=28, train_loss_step=4.060]Epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 26/68 [00:02<00:03, 12.82it/s, v_num=28, train_loss_step=5.470]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 27/68 [00:02<00:03, 12.86it/s, v_num=28, train_loss_step=5.470]Epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 27/68 [00:02<00:03, 12.86it/s, v_num=28, train_loss_step=4.910]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 28/68 [00:02<00:03, 12.89it/s, v_num=28, train_loss_step=4.910]Epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 28/68 [00:02<00:03, 12.89it/s, v_num=28, train_loss_step=4.590]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 29/68 [00:02<00:03, 12.88it/s, v_num=28, train_loss_step=4.590]Epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 29/68 [00:02<00:03, 12.88it/s, v_num=28, train_loss_step=6.060]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/68 [00:02<00:02, 12.87it/s, v_num=28, train_loss_step=6.060]Epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/68 [00:02<00:02, 12.87it/s, v_num=28, train_loss_step=6.120]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 31/68 [00:02<00:02, 12.90it/s, v_num=28, train_loss_step=6.120]Epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 31/68 [00:02<00:02, 12.89it/s, v_num=28, train_loss_step=5.120]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 32/68 [00:02<00:02, 12.97it/s, v_num=28, train_loss_step=5.120]Epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 32/68 [00:02<00:02, 12.97it/s, v_num=28, train_loss_step=4.720]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 33/68 [00:02<00:02, 12.96it/s, v_num=28, train_loss_step=4.720]Epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 33/68 [00:02<00:02, 12.96it/s, v_num=28, train_loss_step=4.310]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 34/68 [00:02<00:02, 13.05it/s, v_num=28, train_loss_step=4.310]Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 34/68 [00:02<00:02, 13.05it/s, v_num=28, train_loss_step=5.000]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/68 [00:02<00:02, 13.12it/s, v_num=28, train_loss_step=5.000]Epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/68 [00:02<00:02, 13.12it/s, v_num=28, train_loss_step=5.970]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 36/68 [00:02<00:02, 13.15it/s, v_num=28, train_loss_step=5.970]Epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 36/68 [00:02<00:02, 13.15it/s, v_num=28, train_loss_step=3.250]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 37/68 [00:02<00:02, 13.15it/s, v_num=28, train_loss_step=3.250]Epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 37/68 [00:02<00:02, 13.14it/s, v_num=28, train_loss_step=4.120]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 38/68 [00:02<00:02, 13.06it/s, v_num=28, train_loss_step=4.120]Epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 38/68 [00:02<00:02, 13.06it/s, v_num=28, train_loss_step=5.750]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 39/68 [00:02<00:02, 13.06it/s, v_num=28, train_loss_step=5.750]Epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 39/68 [00:02<00:02, 13.05it/s, v_num=28, train_loss_step=5.250]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/68 [00:03<00:02, 13.08it/s, v_num=28, train_loss_step=5.250]Epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/68 [00:03<00:02, 13.08it/s, v_num=28, train_loss_step=5.090]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/68 [00:03<00:02, 13.11it/s, v_num=28, train_loss_step=5.090]Epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/68 [00:03<00:02, 13.11it/s, v_num=28, train_loss_step=5.000]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 42/68 [00:03<00:01, 13.10it/s, v_num=28, train_loss_step=5.000]Epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 42/68 [00:03<00:01, 13.10it/s, v_num=28, train_loss_step=6.940]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 43/68 [00:03<00:01, 13.14it/s, v_num=28, train_loss_step=6.940]Epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 43/68 [00:03<00:01, 13.13it/s, v_num=28, train_loss_step=5.000]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 44/68 [00:03<00:01, 13.18it/s, v_num=28, train_loss_step=5.000]Epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 44/68 [00:03<00:01, 13.18it/s, v_num=28, train_loss_step=6.160]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 45/68 [00:03<00:01, 13.20it/s, v_num=28, train_loss_step=6.160]Epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 45/68 [00:03<00:01, 13.20it/s, v_num=28, train_loss_step=4.560]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 46/68 [00:03<00:01, 13.21it/s, v_num=28, train_loss_step=4.560]Epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 46/68 [00:03<00:01, 13.21it/s, v_num=28, train_loss_step=4.160]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 47/68 [00:03<00:01, 13.17it/s, v_num=28, train_loss_step=4.160]Epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 47/68 [00:03<00:01, 13.17it/s, v_num=28, train_loss_step=4.750]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 48/68 [00:03<00:01, 13.21it/s, v_num=28, train_loss_step=4.750]Epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 48/68 [00:03<00:01, 13.21it/s, v_num=28, train_loss_step=4.940]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 49/68 [00:03<00:01, 13.28it/s, v_num=28, train_loss_step=4.940]Epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 49/68 [00:03<00:01, 13.28it/s, v_num=28, train_loss_step=5.470]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 50/68 [00:03<00:01, 13.30it/s, v_num=28, train_loss_step=5.470]Epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 50/68 [00:03<00:01, 13.30it/s, v_num=28, train_loss_step=5.060]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/68 [00:03<00:01, 13.29it/s, v_num=28, train_loss_step=5.060]Epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/68 [00:03<00:01, 13.29it/s, v_num=28, train_loss_step=5.840]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 52/68 [00:03<00:01, 13.31it/s, v_num=28, train_loss_step=5.840]Epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 52/68 [00:03<00:01, 13.31it/s, v_num=28, train_loss_step=4.970]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 53/68 [00:03<00:01, 13.31it/s, v_num=28, train_loss_step=4.970]Epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 53/68 [00:03<00:01, 13.31it/s, v_num=28, train_loss_step=5.720]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 54/68 [00:04<00:01, 13.31it/s, v_num=28, train_loss_step=5.720]Epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 54/68 [00:04<00:01, 13.31it/s, v_num=28, train_loss_step=4.160]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 55/68 [00:04<00:00, 13.31it/s, v_num=28, train_loss_step=4.160]Epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 55/68 [00:04<00:00, 13.31it/s, v_num=28, train_loss_step=4.970]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 56/68 [00:04<00:00, 13.33it/s, v_num=28, train_loss_step=4.970]Epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 56/68 [00:04<00:00, 13.33it/s, v_num=28, train_loss_step=4.560]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 57/68 [00:04<00:00, 13.27it/s, v_num=28, train_loss_step=4.560]Epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 57/68 [00:04<00:00, 13.27it/s, v_num=28, train_loss_step=6.440]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 58/68 [00:04<00:00, 13.25it/s, v_num=28, train_loss_step=6.440]Epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 58/68 [00:04<00:00, 13.25it/s, v_num=28, train_loss_step=5.000]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 59/68 [00:04<00:00, 13.26it/s, v_num=28, train_loss_step=5.000]Epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 59/68 [00:04<00:00, 13.26it/s, v_num=28, train_loss_step=5.000]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 60/68 [00:04<00:00, 13.26it/s, v_num=28, train_loss_step=5.000]Epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 60/68 [00:04<00:00, 13.26it/s, v_num=28, train_loss_step=5.530]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 61/68 [00:04<00:00, 13.28it/s, v_num=28, train_loss_step=5.530]Epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 61/68 [00:04<00:00, 13.28it/s, v_num=28, train_loss_step=5.750]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 62/68 [00:04<00:00, 13.33it/s, v_num=28, train_loss_step=5.750]Epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 62/68 [00:04<00:00, 13.33it/s, v_num=28, train_loss_step=6.030]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 63/68 [00:04<00:00, 13.33it/s, v_num=28, train_loss_step=6.030]Epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 63/68 [00:04<00:00, 13.33it/s, v_num=28, train_loss_step=6.410]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 64/68 [00:04<00:00, 13.33it/s, v_num=28, train_loss_step=6.410]Epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 64/68 [00:04<00:00, 13.33it/s, v_num=28, train_loss_step=4.560]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 65/68 [00:04<00:00, 13.30it/s, v_num=28, train_loss_step=4.560]Epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 65/68 [00:04<00:00, 13.30it/s, v_num=28, train_loss_step=5.120]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 66/68 [00:04<00:00, 13.25it/s, v_num=28, train_loss_step=5.120]Epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 66/68 [00:04<00:00, 13.25it/s, v_num=28, train_loss_step=6.530]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 67/68 [00:05<00:00, 13.24it/s, v_num=28, train_loss_step=6.530]Epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 67/68 [00:05<00:00, 13.24it/s, v_num=28, train_loss_step=4.500]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:05<00:00, 13.22it/s, v_num=28, train_loss_step=4.500]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:05<00:00, 13.21it/s, v_num=28, train_loss_step=4.160]
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation: |          | 0/? [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/18 [00:00<?, ?it/s][A
Validation DataLoader 0:   6%|â–Œ         | 1/18 [00:00<00:00, 32.76it/s][A
Validation DataLoader 0:  11%|â–ˆ         | 2/18 [00:00<00:00, 23.97it/s][A
Validation DataLoader 0:  17%|â–ˆâ–‹        | 3/18 [00:00<00:00, 28.10it/s][A
Validation DataLoader 0:  22%|â–ˆâ–ˆâ–       | 4/18 [00:00<00:00, 30.73it/s][A
Validation DataLoader 0:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:00<00:00, 32.64it/s][A
Validation DataLoader 0:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:00<00:00, 34.05it/s][A
Validation DataLoader 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:00<00:00, 34.97it/s][A
Validation DataLoader 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:00<00:00, 35.77it/s][A
Validation DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:00<00:00, 36.50it/s][A
Validation DataLoader 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:00<00:00, 37.52it/s][A
Validation DataLoader 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:00<00:00, 38.12it/s][A
Validation DataLoader 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:00<00:00, 38.50it/s][A
Validation DataLoader 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:00<00:00, 38.89it/s][A
Validation DataLoader 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:00<00:00, 39.24it/s][A
Validation DataLoader 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:00<00:00, 39.48it/s][A
Validation DataLoader 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:00<00:00, 39.01it/s][A
Validation DataLoader 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:00<00:00, 39.27it/s][A
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 39.42it/s][A
                                                                        [AEpoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:06<00:00,  9.97it/s, v_num=28, train_loss_step=4.160, val_loss=4.920]Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:06<00:00,  9.97it/s, v_num=28, train_loss_step=4.160, val_loss=4.920, train_loss_epoch=5.240]`Trainer.fit` stopped: `max_epochs=1` reached.
Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:06<00:00,  9.97it/s, v_num=28, train_loss_step=4.160, val_loss=4.920, train_loss_epoch=5.240]ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

Validation ROC-AUC: 0.5124
